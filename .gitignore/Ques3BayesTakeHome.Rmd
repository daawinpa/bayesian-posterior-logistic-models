---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

Question 3
Recall the putts data from class. The R notebook posted from December 2 presents two models: a logistic
model and a "physical" model. Suppose we wished to incorporate the following prior expert opinion into our
models:
. My best guess for the probability of making a 5-foot putt is 52.5%; however, there is a 95% chance that
this probability is below 71.6%.
. My best guess for the probability of making a 10-foot putt is 27.8%; however, there is a 95% chance that
this probability is below 40.8%.


a) Re-fit both models incorporating this prior information. Plot the data with 95% posterior credible
bands for the probabilities of successful putts. (You do not need to provide posterior predictive bands.)

```{r}
setwd("C:/Users/Palma/Desktop/MS STATS/Year2 Sem1/Bayesian/FinalTakehome")
library(rstan)
load("putts.RData")
set.seed(1202)
attach(putts)
putts
```


Let's try to fit a simple logistic model to these data:
$$
\begin{split}
  & y_x \overset{ind}{\sim} Binomial(n_x,p_x) \\
  & \ln\left(\frac{p_x}{1-p_x}\right) = \beta_0+\beta_1(x-7),\quad x\in\{2,3,\ldots,20\}.
\end{split}
$$
```{r}
getthetaprior <- function(bg,hi){
# Interpreting bg as the mode of a Beta(a,b) distribution,
# we determine that b = (a-1+bg(2-a))/bg. Furthermore, we want
# the 95th percentile of this beta distribution to be hi.
f <- function(a) { pbeta(hi,a,(a-1-bg*(a-2))/bg)-.95 }
a <- uniroot(f,c(1,3000))$root
b <- (a-1-bg*(a-2))/bg
return(c(a,b))
}
  ab5 <- getthetaprior(.525,.716)
  ab10 <- getthetaprior(.278,.408)  
```


Based on expert opinion, our priors for $\theta_{5}$ and $\theta_{10}$ are as follows:

*   $\theta_{5} \sim Beta(`r round(ab5[1],2)`,`r round(ab5[2],2)`)$.
*   $\theta_{10} \sim Beta(`r round(ab10[1],2)`,`r round(ab10[2],2)`)$.



How would we use these priors on different $\theta$s to induce priors on $\beta_0$ and $\beta_1$? For each simulated $\left(\theta_{10}\theta_{5}\right)$ pair, we have:

$$
\begin{split}
& \begin{pmatrix} F^{-1}(\theta_{5}) \\ F^{-1}(\theta_{10}) \end{pmatrix}
= \begin{pmatrix}1 & -2 \\ 1 & 3\end{pmatrix}\begin{pmatrix}\beta_0 \\ \beta_1\end{pmatrix} \\
& \implies
\begin{pmatrix}\beta_0 \\ \beta_1\end{pmatrix} = \begin{pmatrix}1 & -2 \\ 1 & 3\end{pmatrix}^{-1}\begin{pmatrix} F^{-1}(\theta_{5}) \\ F^{-1}(\theta_{10}) \end{pmatrix}
= \begin{pmatrix}.6 & .4 \\ -.2 & .2\end{pmatrix}\begin{pmatrix} F^{-1}(\theta_{5}) \\ F^{-1}(\theta_{10}) \end{pmatrix}
= \begin{pmatrix}.6\,F^{-1}(\theta_{5}) + .4\,F^{-1}(\theta_{10}) \\ -.2\,F^{-1}(\theta_{5}) + .2\,F^{-1}(\theta_{10})\end{pmatrix}
\end{split}
$$
```{r}
solve(rbind(c(1,-2),c(1,3)))
```



```{r, message=FALSE,warning=FALSE}
### Model 1 - "Logistic model"
set.seed(505)
mod1code <- '
  data{
    int<lower=1>         n[19];
    int<lower=0>         y[19];
    real<lower=0>        x[19];
  }
  parameters{
   real<lower=0,upper=1> theta5;  // 
  real<lower=0,upper=1> theta10;  //
  }
 transformed parameters{
  real<lower=0,upper=1> p[19];
  real b0;
  real b1;

  // For logistic regression, Finv is the logit function
  b0 = .6*logit(theta5)+.4*logit(theta10);
  b1 = -.2*logit(theta5)+.2*logit(theta10);
    
    for(i in 1:19){
      p[i] = inv_logit(b0+b1*(x[i]-7));
    }
  }
  model{
  theta5 ~ beta(8.744599,8.007018);
  theta10 ~ beta(12.10458,29.83995);

for(i in 1:19){
      y[i] ~ binomial(n[i],p[i]);
  }
  }
'

mod1dat <- with(putts,list(n=n,y=y,x=distance))
mod1 <- stan(model_code=mod1code, data=mod1dat)
print(mod1,digits=5)
```

```{r}
# Print and plot the results
mod1
p <- extract(mod1)$p

with(putts,plot(y/n~distance,pch=16,
                main="Logistic Model Fit",
                ylim=c(0,1),bty="l",
                xlab="Distance (ft)",
                ylab="Proportion successful"))
lines(2:20,colMeans(p),lwd=2)
lines(2:20,apply(p,2,quantile,.025),col="red",lty=2)
lines(2:20,apply(p,2,quantile,.975),col="red",lty=2)
```
$$
p_x = P\left[|\theta|\leq \sin^{-1}\left(\frac{R-r}{x}\right)\right]
=P\left[|Z|\leq\frac{1}{\sigma}\sin^{-1}\left(\frac{R-r}{x}\right)\right]
=2\Phi\left(\frac{1}{\sigma}\sin^{-1}\left(\frac{R-r}{x}\right)\right)-1,
$$
where $Z$ is a standard normal random variable and $\Phi$ is the CDF of the standard normal distribution.


##### Prior on $\sigma$
Our initial  prior distribution on the parameter $\sigma$ is $\sigma \sim Uniform\left(0,\frac{\pi}{6}\right)$ . Using expert inofrmation 
My best guess for the probability of making a 10-foot putt is 27.8%; however, there is a 95% chance that this probability is below 40.8%.
To incorporate  prior information about  $\sigma$ we can manipulate this information and obtain the result below;

$$
P\left[2\Phi\left(\frac{1}{\sigma}\sin^{-1}\left(\frac{R-r}{x}\right)\right)-1 \leq.408\right]=0.95 
$$

We solve and obtain an expression for  $\sigma$

$$
P\left[\frac{1}{\sigma}\leq \frac{\Phi^{-1}(0.704)}{\sin^{-1}\left(\frac{R-r}{10}\right)} \right]=0.95 
$$



```{r}
##compute sigma95

sigma95= 1/(qnorm(.5*(0.408+1))*1/(asin(0.1*(4.25/24-1.68/24))))

```



$$ \quad \implies \quad P(\sigma >`r round(sigma95,3)`) = .95.$$
$$ \quad \implies \quad 1-F_\sigma(sigma95) = .95.$$

Thus since the prior of $\sigma$ is a uniform distribution we can obtain apporpriate bounds on the uniform distribution, so our informative  prior distirbution on $\sigma$ is $Uniform (0,0.3996)$. That is the distance of b-a of a Uniform (a,b) distribution.



```{r, message=FALSE,warning=FALSE}
### Model 2 - "Physical model"
set.seed(507)
mod2code <- '
  data{
    real<lower=0>        smallr;
    real<lower=smallr>   bigR;
    int<lower=1>         n[19];
    int<lower=0>         y[19];
    real<lower=0>        x[19];
  }
  parameters{
    real<lower=0> sigma;
  }
  transformed parameters{
    real<lower=0,upper=1> p[19];

    for(i in 1:19){
      p[i] = 2*Phi(asin((bigR-smallr)/x[i])/sigma) - 1;
    }
  }
  model{
    sigma ~ uniform(0,.3996);
    for(i in 1:19){
      y[i] ~ binomial(n[i],p[i]);
    }
  }
'
smallr <- 1.68/24   ## A reg golf ball has diameter 1.68 in; we convert to ft
bigR <- 4.25/24     ## A reg golf hole has diameter 4.25 in; we convert to feet

mod2dat <- with(putts,list(smallr=smallr,bigR=bigR,y=y,n=n,x=distance))
mod2 <- stan(model_code=mod2code,data=mod2dat)
print(mod2)
```
```{r}
mod2
p2 <- extract(mod2)$p
# Re-plot the earlier plot, and add the prediction intervals
with(putts,plot(y/n~distance,pch=16,
                main="Physical Model Fit",
                ylim=c(0,1),bty="l",
                xlab="Distance (ft)",
                ylab="Proportion successful"))
lines(2:20,colMeans(p2),lwd=2)
lines(2:20,apply(p2,2,quantile,.025),col="red",lty=2)
lines(2:20,apply(p2,2,quantile,.975),col="red",lty=2)

```

b) Compare the fits of the two models using a Bayes factor. What do you conclude?


Code following this procedure for computing Bayes factors for each pair of models is given below.

```{r}
#useful functions 
logit <- function(x) { log(x/(1-x)) }
invlogit <- function(x) { exp(x)/(1+exp(x)) }


# Generate large random samples of theta5 and theta10
th5 <- rbeta(10000,ab5[1],ab5[2])
th10 <- rbeta(10000,ab10[1],ab10[2])

## For each pair of thetas, generate the beta coefficients for each model

# Logistic
b01 <- .6*logit(th5)+.4*logit(th10)
b11 <- -.2*logit(th5)+.2*logit(th10)

# Physical  ################################
smallr <- 1.68/24   ## A reg golf ball has diameter 1.68 in; we convert to ft
bigR <- 4.25/24   ## A reg golf hole has diameter 4.25 in; we convert to feet
sigma<-0.03   ### mean of the posterior distribution of sigma

## Calculate ln f(y|beta,model) for each sampled beta for each model.
## Exponentiate these to obtain f(y|beta,model) for each beta for each model,
## and take their average to obtain an estimate of f(y|model) for each model.

# Logistic
putssuc<-putts$y/putts$n
thetas1 <- invlogit(b01 + b11 %*% t(distance-7)) 
logfyb1 <- log(thetas1) %*% putssuc + log(1-thetas1) %*% (1-putssuc) ###
fyb1 <- mean(exp(logfyb1)) 

# Physical 
thetas2<-   2*pnorm(asin((bigR-smallr)/distance)/sigma)-1  
logfyb2 <- log(thetas2) %*% putssuc + log(1-thetas2) %*% (1-putssuc) ##
fyb2 <- mean(exp(logfyb2))

## Estimate the Bayes factors for each pair of models:
BF12 <- fyb1/fyb2
BF12

``` 
Hence we can see that , given the expert's prior information, the two  models perform  differently .  It  appears that the physical model  performs better than the Logistic model.
